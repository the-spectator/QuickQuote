{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import re\n",
    "from datetime import datetime\n",
    "#from search_term import give_med_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = r'\\d{2,3}'\n",
    "gender = r'(\\b[Mm]ale?)|(\\b[Ff]emale?)|(\\bFEMALE)|(\\bMALE)|(/b)|F/|M/'\n",
    "Date = r'(([A-Z0-9][A-Z0-9]?[/-])?[A-Z0-9][A-Z0-9]?[/-][A-Z0-9][A-Z0-9][A-Z0-9]?[A-Z0-9]?)|([A-Za-z][A-Za-z][A-Za-z]\\s..?[,]\\s....)'\n",
    "DOB  = r'(.*)?DOB|[Dd][aA][tT][eE]\\s[oO][fF]\\s[Bb][iI][rR][tT][hH]\\s?(.*)?'\n",
    "year_four_digit = r'\\b(19|20)\\d{2}(w+)?'\n",
    "year_two_digit = r'\\d{2}$(w+)?'\n",
    "product_type = r'(\\b[Pp]roduct\\s[Tt]ype):\\s?.*'\n",
    "permanent = r'[Pp][eE][rR][mM]([aA][nN][aA][nN][tT])?'\n",
    "term = r'[tT][eE][rR][mM]'\n",
    "\n",
    "#Assuming USA currency dollar\n",
    "amount_with_dollar = r'(\\$\\s?\\d{1,3}(,\\d{2,3})*(\\.\\d+)?)(\\s?[kK]?)(\\s?[mM]?[mM]?(illion)?(ILLION)?)([bB]?)'\n",
    "amount_without_dollar = r'(\\$?\\s?\\d{1,3}(,\\d{2,3})*(\\.\\d+)?)(\\s?[kK]?)(\\s[mM]?[mM]?(illion)?(ILLION)?)([bB]?)((\\s?[Yy][Ee][aA][rR][sS]?)?)'\n",
    "faceamount = r'(\\b[Ff]ace\\s?[Aa]mount:?\\s?.*)'\n",
    "termamount = r'(.*)?[Tt][eE][rR][mM](.*)?'   \t\t\t#Regex to read single line from first newline to next newline\n",
    "seeking = r'(.*)?[Ss][eE][eE][kK]([iI][nN][gG])?(.*)?'\n",
    "term_year = r'(y(ea)?r|Y(ea)?r|Y(ea)?r)'\n",
    "k_conv = r'(\\s?[kK])'\n",
    "m_conv = r'(\\s?[mM][mM]?(illion)?(ILLION)?)'\n",
    "num_conv = r'\\d{1,3}'\n",
    "\n",
    "weight = r'(.*)?\\b[wW][eE][iI][gG][hH][tT]\\s?(.*)?' \n",
    "weight_num = r'(\\d*\\.?\\d+)\\s?(lb|lbs|Lbs|LB|LBS|kg|Kg|KG|#)'\t\t#r'(.*)\\s?([lL][bB][sS]|[oO][zZ]|[gG]|[kK][Gg])' \n",
    "\n",
    "age_simple = r'(.*)?[Aa][Gg][Ee]\\s?(.*)?'\n",
    "age = r'(.*\\s?[Yy]([eE][aA])?[rR]?[sS]?\\s?([oO][lL][dD])?)'\n",
    "age_from_gender = r'(.*)?(\\b[Mm]ale?)|(\\b[Ff]emale?)|(\\bFEMALE)|(\\bMALE)|(/b)\\s?(.*)?' \n",
    "\n",
    "height_num = r'\\d{1,2}'\n",
    "height1 = r'((.*)?\\s?([Ff][eE][eE][tT])((.*)?\\s?([iI][nN][Cc][Hh][Ee][Ss]))?)'\n",
    "height2 = r'.[\\'|\\’](\\s?.[\\\"|\\”])?' \n",
    "feet = r'\\d[\\'|\\’]'\n",
    "inches = r'\\d[\\\"|\\”]' \n",
    "\n",
    "preferred = r'(.*)?(Preferred|preferred)\\s?(.*)?'\n",
    "height_word = r'Height|height'\n",
    "weight_word = r'Weight|weight' \n",
    "\n",
    "build = r'(Build|build)\\s?(.*)?'\n",
    "build_weight = r'\\d{3}'\n",
    "build_height = r'\\d\\.\\d'\n",
    "\n",
    "smoker = r'(.*)?[sS][Mm][oO][Kk]\\s?(.*)?' \n",
    "tobacco = r'(.*)?[Tt][oO][bB][aA][cC][cC][oO]\\s?(.*)?'\n",
    "no = r'[nN][oO]'\n",
    "\n",
    "med = r'(.*)?\\b[mM][eE][dD][iI][cC][aA][tT][iI][oO][nN]\\s?(.*)?'\n",
    "\n",
    "family = r'(.*)?(\\b[Ff]amily)\\s?(.*)?'\n",
    "family_member = r'(.*)?(\\b[Mm]om)|(\\b[Ff]ather)|(\\b[Dd]ad)|(\\b[Ss]ister)|(\\b[Bb]rother)|(\\b[Hh]usband)|(\\b[Ww]ife)\\s?(.*)?'\n",
    "\n",
    "lives = r'(.*)?(\\b[Ll]ives)\\s?(.*)?'\n",
    "prop = r'(.*)?(\\b[Pp]roperty)\\s?(.*)?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(st,i):\n",
    "    for line in st: #iterate through every line\n",
    "        #return list of entities in that line\n",
    "        num = re.search(number, line, re.I | re.U)\n",
    "        x=0\n",
    "        x = re.search(Date, line, re.I | re.U)\n",
    "#Gender\n",
    "        y = re.search(gender, line, re.I | re.U)\n",
    "        if(y):\n",
    "            if(y.group(0)=='F/' or y.group(0)=='f/'):\n",
    "                data[i][0]='Female'\n",
    "            elif(y.group(0)=='M/' or y.group(0)=='m/'):\n",
    "                data[i][0]='Male'\n",
    "            else:\n",
    "\n",
    "                data[i][0]=(y.group(0))\n",
    "        elif(y and num):\n",
    "            data[i][0]=(y.group(0))\n",
    "        else:\n",
    "            data[i][0]=\" \"\n",
    "\n",
    "#Year for DOB\n",
    "        z = 0\n",
    "        x1 = re.search(year_four_digit, line, re.I | re.U)\n",
    "        if(x):\n",
    "            x1 = re.search(year_four_digit, x.group(0), re.I | re.U)\n",
    "            x2 = re.search(year_two_digit, x.group(0), re.I | re.U)\n",
    "            if(x1):\n",
    "                data[i][1]=x1.group(0)\n",
    "            elif(x2):\n",
    "                z = x2.group(0)\n",
    "                data[i][1] = '19'+z\n",
    "        elif(x1):\n",
    "            x1 = re.search(year_four_digit, line, re.I | re.U)\n",
    "\n",
    "            data[i][1]=x1.group(0)\n",
    "        else:\n",
    "            data[i][1]=\" \"\n",
    "\n",
    "#Age in years\n",
    "        age_reg = re.search(age, line, re.I | re.U)\n",
    "        age_simple_reg = re.search(age_simple, line, re.I | re.U)\n",
    "        dob = re.search(DOB, line, re.I | re.U)\n",
    "        age_gender_reg = re.search(age_from_gender, line, re.I | re.U)\n",
    "\n",
    "        if(age_gender_reg):\n",
    "                am = re.search(number, age_gender_reg.group(0), re.I | re.U)\n",
    "                if(am):\n",
    "                    data[i][2]=am.group(0)\n",
    "\n",
    "        if(x1):#20/03/1996\n",
    "\n",
    "            currentYear = datetime.now().year\n",
    "\n",
    "            data[i][2]=((currentYear-(int)(x1.group(0))))\n",
    "\n",
    "        else:\n",
    "            if(x1 and dob):#DOB 20/03/1996\n",
    "\n",
    "                currentYear = datetime.now().year\n",
    "\n",
    "                data[i][2]=((currentYear-(int)(x1.group(0))))\n",
    "            elif(x1 and y):#Male 20/03/1996\n",
    "\n",
    "                currentYear = datetime.now().year\n",
    "\n",
    "                data[i][2]=((currentYear-(int)(x1.group(0))))\n",
    "\n",
    "            else:\n",
    "                data[i][2]=' '\n",
    "\n",
    "            if(age_reg):#20 years ago\n",
    "                age_num = age_reg.group(0)\n",
    "                an = re.search(number, age_num, re.I | re.U)\n",
    "                if(an):\n",
    "\n",
    "                    data[i][2]=(an.group(0))\n",
    "\n",
    "            if(age_simple_reg):#Age 20\n",
    "                age_num = age_simple_reg.group(0)\n",
    "                an = re.search(number, age_num, re.I | re.U)\n",
    "                if(an):\n",
    "\n",
    "                    data[i][2]=(an.group(0))\n",
    "\n",
    "            if((data[i][2]<'18') and data[i][1]!=\" \"):#From Year of Birth\n",
    "                currentYear = datetime.now().year\n",
    "                data[i][2]=(currentYear-(int)(data[i][1]))\n",
    "\n",
    "#Product Type\n",
    "        z=re.search(product_type, line, re.I | re.U)\n",
    "        perm_reg = re.search(permanent, line, re.I | re.U)\n",
    "        term_type_reg = re.search(term, line, re.I | re.U)\n",
    "        if(z): \n",
    "\n",
    "            data[i][3]=(z.group(0))\n",
    "        elif(perm_reg):\n",
    "            final_str = \"Product Type: Permanent\"\n",
    "            data[i][3]=(final_str)\n",
    "        elif(term_type_reg):\n",
    "            final_str = \"Product Type: Term\"\n",
    "            data[i][3]=(final_str)\n",
    "        else:\n",
    "            data[i][3]=\" \"\n",
    "            \n",
    "        w = re.search(faceamount, line, re.I | re.U)\n",
    "        term_reg = re.search(termamount, line, re.I | re.U)\n",
    "        seek_reg = re.search(seeking, line, re.I | re.U)\n",
    "#With faceAmount\n",
    "        if(w):\n",
    "            k = re.search(k_conv, w.group(0), re.I | re.U)\n",
    "            if(k):\n",
    "                nn = re.search(num_conv, w.group(0), re.I | re.U)\n",
    "                if(nn):\n",
    "                    data[i][4]='Face Amount: $'+((nn.group(0))+',000')\n",
    "            else:\n",
    "                data[i][4]=(w.group(0))\n",
    "\n",
    "\n",
    "#With term Amount\n",
    "        elif(term_reg):\n",
    "            amd = re.search(amount_with_dollar, term_reg.group(0), re.I | re.U)\n",
    "            amwd = re.search(amount_without_dollar, term_reg.group(0), re.I | re.U)\t\t\t#Find 2nd regex in the same line of 1st regex \n",
    "            z = 0\n",
    "            if(amd):\n",
    "                k = re.search(k_conv, amd.group(0), re.I | re.U)\n",
    "                m = re.search(m_conv, amd.group(0), re.I | re.U)\n",
    "                if(k):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000')\n",
    "                elif(m):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000,000')\n",
    "                else:\n",
    "                    data[i][4]='Face Amount: '+amd.group(0)\n",
    "            elif(amwd):\n",
    "                term_year_reg = re.search(term_year, amwd.group(0), re.I | re.U)\n",
    "                if(term_year_reg):\n",
    "                    data[i][4]='Term Year: '+(amwd.group(0))\n",
    "                else:\n",
    "#data[i][4]='Face Amount: $'+(amwd.group(0))\n",
    "                    k = re.search(k_conv, amwd.group(0), re.I | re.U)\n",
    "                    m = re.search(m_conv, amwd.group(0), re.I | re.U)\n",
    "                    if(k):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000')\n",
    "                    elif(m):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000,000')\n",
    "                    else:\n",
    "                        data[i][4]='Face Amount: $'+amwd.group(0)\n",
    "#With Seeking\n",
    "        elif(seek_reg):\n",
    "            amd = re.search(amount_with_dollar, seek_reg.group(0), re.I | re.U)\n",
    "            amwd = re.search(amount_without_dollar, seek_reg.group(0), re.I | re.U)\t\t\t#Find 2nd regex in the same line of 1st regex \n",
    "            if(amd):\n",
    "#data[i][4]='Face Amount: '+(amd.group(0))\n",
    "                k = re.search(k_conv, amd.group(0), re.I | re.U)\n",
    "                m = re.search(m_conv, amd.group(0), re.I | re.U)\n",
    "                if(k):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000')\n",
    "                elif(m):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000,000')\n",
    "                else:\n",
    "                    data[i][4]='Face Amount: '+amd.group(0)\n",
    "            elif(amwd):\n",
    "                term_year_reg = re.search(term_year, amwd.group(0), re.I | re.U)\n",
    "                if(term_year_reg):\n",
    "                    data[i][4]='Term Year: '+(amwd.group(0))\n",
    "                else:\n",
    "#data[i][4]='Face Amount: $'+(amwd.group(0))\n",
    "                    k = re.search(k_conv, amwd.group(0), re.I | re.U)\n",
    "                    m = re.search(m_conv, amwd.group(0), re.I | re.U)\n",
    "                    if(k):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000')\n",
    "                    elif(m):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000,000')\n",
    "                    else:\n",
    "                        data[i][4]='Face Amount: $'+amwd.group(0)\n",
    "        else:\n",
    "            data[i][4]=\" \"\n",
    "\n",
    "\n",
    "#Weight\n",
    "        x=re.search(weight_num, line, re.I | re.U) \n",
    "        wt=re.search(weight, line, re.I | re.U)\n",
    "        if(x): \n",
    "#print (x.group(0)+\"\\n\")\n",
    "            data[i][5]=(x.group(0))\n",
    "        elif(wt):\n",
    "            am = re.search(weight_num,wt.group(0), re.I | re.U)\n",
    "            if(am):\n",
    "                data[i][5]=(am.group(0))\n",
    "        else:\n",
    "            data[i][5]=\" \"\n",
    "\n",
    "#Height\n",
    "        ht = re.search(height1, line, re.I | re.U)\n",
    "        htsym = re.search(height2, line, re.I | re.U)\n",
    "        if(ht): \n",
    "\n",
    "            data[i][6]=(ht.group(0))\n",
    "        elif(htsym):\n",
    "            f = re.search(feet, (htsym.group(0)), re.I | re.U)\n",
    "            inch = re.search(inches, (htsym.group(0)), re.I | re.U)\n",
    "            if(f):\n",
    "\n",
    "                am = re.search(height_num, (f.group(0)), re.I | re.U).group(0) + ' Feet'\n",
    "                if(i):\n",
    "                    am+=re.search(height_num, (inch.group(0)), re.I | re.U).group(0) + ' Inches' \n",
    "                data[i][6]=am\n",
    "        else:\n",
    "            data[i][6]=\" \"\n",
    "\n",
    "#Preferred Height & Weight\n",
    "        pr = ''\n",
    "        pr = re.search(preferred, line, re.I | re.U)\n",
    "        if(pr!='' and pr):\n",
    "            h_reg = re.search(height_word, pr.group(0), re.I | re.U)\n",
    "            if(h_reg):\n",
    "                data[i][6] = \"5 Feet 9 Inches\"\n",
    "            w_reg = re.search(weight_word, pr.group(0), re.I | re.U)\n",
    "            if(w_reg):\n",
    "                data[i][5] = \"196 lbs\"\n",
    "\n",
    "#Height & Weight from build\n",
    "        bu = ''\n",
    "        bu = re.search(build, line, re.I | re.U)\n",
    "        if(bu):\n",
    "            h_reg = re.search(build_height, bu.group(0), re.I | re.U)\n",
    "            if(h_reg):\n",
    "                data[i][6] = h_reg.group(0) + ' Feet'\n",
    "                h =' '\n",
    "            w_reg = re.search(build_weight, bu.group(0), re.I | re.U)\n",
    "            if(w_reg):\n",
    "                data[i][5] = w_reg.group(0)+ ' lbs'\n",
    "                w = ' '\n",
    "\n",
    "#Habit\n",
    "        sm = re.search(smoker, line, re.I | re.U)\n",
    "        tob = re.search(tobacco, line, re.I | re.U)\n",
    "        if(sm): \n",
    "            if(re.search(no, sm.group(0), re.I | re.U)):\n",
    "                data[i][7]=\"Non-Smoker\"\n",
    "            else:\n",
    "                data[i][7]=\"Smoker\"\n",
    "        elif(tob):\n",
    "\n",
    "            if(re.search(no, tob.group(0), re.I | re.U)):\n",
    "                data[i][7]=\"Non-Tobacco\"\n",
    "            else:\n",
    "                data[i][7]=\"Tobacco\"\n",
    "        else:\n",
    "            data[i][7]=\" \"\n",
    "\n",
    "\n",
    "#Medication & Treatment\n",
    "        med_reg = (re.search(med,line, re.I | re.U))\n",
    "        if(med_reg):\n",
    "            if(re.search(no, med_reg.group(0), re.I | re.U)):\n",
    "                data[i][8]=\"No Medication\"\n",
    "                \n",
    "        else:#Write else outsite condition (to stop rewriting of above cell)\n",
    "            data[i][8]=\"\"\n",
    "\n",
    "#Family\n",
    "        family_reg = (re.search(family,line, re.I | re.U))\n",
    "        family_member_reg = (re.search(family_member,line, re.I | re.U))\n",
    "        if(family_reg):\n",
    "            data[i][9]=family_reg.groups()\n",
    "            \n",
    "        else:#Write else outsite condition (to stop rewriting of above cell)\n",
    "            data[i][9]=\"\"\n",
    "\n",
    "#Property\n",
    "        lives_reg = (re.search(lives,line, re.I | re.U))\n",
    "        prop_reg = (re.search(prop,line, re.I | re.U))\n",
    "        if(lives_reg):\n",
    "            data[i][10]=lives_reg.groups()\n",
    "            if(prop_reg):\n",
    "                data[i][10]=lives_reg.groups()+prop_reg.groups()\n",
    "        elif(prop_reg):\n",
    "            data[i][10]=prop_reg.groups()\n",
    "            \n",
    "        else:#Write else outsite condition (to stop rewriting of above cell)\n",
    "            data[i][10]=\"\"\n",
    "\n",
    "    data[i][11]=st\n",
    "#medical data\n",
    "        #data[i][11] = give_med_terms(line)\n",
    "\n",
    "    wtr.writerows(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i=0\n",
    "w, h = 12, 1;\n",
    "data = [[\" \" for x in range(w)] for y in range(h)]\n",
    "st = []\n",
    "\n",
    "out = open('regexProcessed.csv', 'w', newline='')\n",
    "wtr= csv.writer( out )\n",
    "wtr.writerow(['Gender','Year_of_birth','Age(years)','Product Type','Face Amount','Weight','Height','Habit','Medication','Family','Property',''])\n",
    "\n",
    "\n",
    "\n",
    "with open('raw_data1.csv','r',encoding=\"ISO-8859-1\") as f:\n",
    "    rows = csv.reader(f)\n",
    "    for row in rows:\n",
    "\n",
    "        st.append(row[8])\n",
    "        reg(st,i)\n",
    "        st=[]\n",
    "          \n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Year_of_birth</th>\n",
       "      <th>Age(years)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Face Amount</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Habit</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Family</th>\n",
       "      <th>Property</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1977</td>\n",
       "      <td>41</td>\n",
       "      <td>Product Type: Permanent</td>\n",
       "      <td>Face Amount: 50,000</td>\n",
       "      <td>200KG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Gender: FEMALE\\nDOB : APR 20, 1977\\nProduct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>1921</td>\n",
       "      <td>97</td>\n",
       "      <td></td>\n",
       "      <td>Face Amount: 250,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Gender: male\\nDOB : 10/00/1921\\nFace Amount:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>200 lb</td>\n",
       "      <td>5 Feet</td>\n",
       "      <td></td>\n",
       "      <td>No Medication</td>\n",
       "      <td>('No significant ', 'family', 'history')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Male\\n01/31/97\\n5' 6Ã\\n200 lb\\nNo medicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>1945</td>\n",
       "      <td>73</td>\n",
       "      <td></td>\n",
       "      <td>Face Amount: $20,000</td>\n",
       "      <td>199#</td>\n",
       "      <td>8 Feet</td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Family', 'hx of RA in Mother and Sister....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Seeking $20,000 LN offered Table C due to ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Product Type: Permanent</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Male 53\\nBuilt Ã¢\\x80\\x93 Preferred NT\\nDiag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>1966</td>\n",
       "      <td>52</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $500,212</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Strong ', 'family', 'history for skin cancer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['General:\\n    -   Client Gender: Female\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: 50,000,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Lives', 'in XXXX XXXX, She is a US Citiz...</td>\n",
       "      <td>['Female, DOB 01/03/1996NS looking for $50m te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MALE</td>\n",
       "      <td>1950</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "      <td>Face Amount: $300,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] QQ: S BarXXXX\\n\\nPlease ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Female</td>\n",
       "      <td>1950</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>255lb</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] Pascarella Case - Potent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Female</td>\n",
       "      <td>1950</td>\n",
       "      <td>35</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $777,000</td>\n",
       "      <td>199 lbs</td>\n",
       "      <td>6.6 Feet</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Household income is 11K, she is a home maker...</td>\n",
       "      <td>['Subject: [External] XXXXX\\n\\nF/age 35, NS, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $555,000</td>\n",
       "      <td>196 lbs</td>\n",
       "      <td>5 Feet 9 Inches</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('           Uses it for pleasure and business...</td>\n",
       "      <td>[\"Subject: [External] Tentative case \\n\\nAgent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Term Year:  22 years</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Male- 22 years old state of 50 looking for 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Female</td>\n",
       "      <td></td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External]Female Age 33 \\n\\nThis me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "      <td>23</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $59,000,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No Medication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] QQ - Zvin\\n\\nPer the age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Male</td>\n",
       "      <td>1995</td>\n",
       "      <td>55</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $1,555,000</td>\n",
       "      <td>255 lb</td>\n",
       "      <td>6 Feet</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Mom had breast cancer at age 65 but all ', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Subject: [External] #secure# Wong quote\\n\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['APS SUMMARY\\nPMH: Subarachnoid Bleed 20X2 no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: 20,000,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Lives', 'in XXXX XXXX, She is a US Citiz...</td>\n",
       "      <td>['Subject: [pSpam] DR QQ\\n\\nFemale, DOB 01/XX/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>55</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Term Year: 20 year</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] Quick quote request - FM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Male</td>\n",
       "      <td>1999</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>199#</td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Family', 'hx of RA in Mother and Sister....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LN offered Table C due to chronic pain histo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Year_of_birth Age(years)             Product Type  \\\n",
       "1   FEMALE          1977         41  Product Type: Permanent   \n",
       "2     male          1921         97                            \n",
       "3     Male          1997         21                            \n",
       "4     Male          1945         73                            \n",
       "5     Male                           Product Type: Permanent   \n",
       "6   Female          1966         52       Product Type: Term   \n",
       "7   Female          1996         22       Product Type: Term   \n",
       "8     MALE          1950         68                            \n",
       "9   Female          1950         68                            \n",
       "10  Female          1950         35       Product Type: Term   \n",
       "11    Male                                Product Type: Term   \n",
       "12    Male                       22       Product Type: Term   \n",
       "13  Female                       33                            \n",
       "14                  1995         23       Product Type: Term   \n",
       "15    Male          1995         55       Product Type: Term   \n",
       "16                  1995         23                            \n",
       "17  Female          1996         22       Product Type: Term   \n",
       "18  Female          1996         55       Product Type: Term   \n",
       "19    Male          1999         19                            \n",
       "\n",
       "                 Face Amount   Weight           Height        Habit  \\\n",
       "1        Face Amount: 50,000    200KG                                 \n",
       "2       Face Amount: 250,000                                          \n",
       "3                              200 lb           5 Feet                \n",
       "4      Face Amount: $20,000      199#           8 Feet  Non-Tobacco   \n",
       "5                                                                     \n",
       "6      Face Amount: $500,212                                Tobacco   \n",
       "7    Face Amount: 50,000,000                            Non-Tobacco   \n",
       "8      Face Amount: $300,000                                          \n",
       "9                               255lb                                 \n",
       "10     Face Amount: $777,000  199 lbs         6.6 Feet                \n",
       "11     Face Amount: $555,000  196 lbs  5 Feet 9 Inches   Non-Smoker   \n",
       "12      Term Year:  22 years                                          \n",
       "13                                                      Non-Tobacco   \n",
       "14  Face Amount: $59,000,000                                          \n",
       "15  Face Amount: $1,555,000    255 lb           6 Feet   Non-Smoker   \n",
       "16                                                                    \n",
       "17   Face Amount: 20,000,000                                          \n",
       "18        Term Year: 20 year                             Non-Smoker   \n",
       "19                               199#                   Non-Tobacco   \n",
       "\n",
       "       Medication                                             Family  \\\n",
       "1             NaN                                                NaN   \n",
       "2             NaN                                                NaN   \n",
       "3   No Medication           ('No significant ', 'family', 'history')   \n",
       "4             NaN  ('', 'Family', 'hx of RA in Mother and Sister....   \n",
       "5             NaN                                                NaN   \n",
       "6             NaN  ('Strong ', 'family', 'history for skin cancer...   \n",
       "7             NaN                                                NaN   \n",
       "8             NaN                                                NaN   \n",
       "9             NaN                                                NaN   \n",
       "10            NaN                                                NaN   \n",
       "11            NaN                                                NaN   \n",
       "12            NaN                                                NaN   \n",
       "13            NaN                                                NaN   \n",
       "14  No Medication                                                NaN   \n",
       "15            NaN  ('Mom had breast cancer at age 65 but all ', '...   \n",
       "16            NaN                                                NaN   \n",
       "17            NaN                                                NaN   \n",
       "18            NaN                                                NaN   \n",
       "19            NaN  ('', 'Family', 'hx of RA in Mother and Sister....   \n",
       "\n",
       "                                             Property  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7   ('', 'Lives', 'in XXXX XXXX, She is a US Citiz...   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  ('Household income is 11K, she is a home maker...   \n",
       "11  ('           Uses it for pleasure and business...   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17  ('', 'Lives', 'in XXXX XXXX, She is a US Citiz...   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "                                          Unnamed: 11  \n",
       "1   ['Gender: FEMALE\\nDOB : APR 20, 1977\\nProduct ...  \n",
       "2   ['Gender: male\\nDOB : 10/00/1921\\nFace Amount:...  \n",
       "3   [\"Male\\n01/31/97\\n5' 6Ã\\n200 lb\\nNo medicatio...  \n",
       "4   [\"Seeking $20,000 LN offered Table C due to ch...  \n",
       "5   ['Male 53\\nBuilt Ã¢\\x80\\x93 Preferred NT\\nDiag...  \n",
       "6   ['General:\\n    -   Client Gender: Female\\n   ...  \n",
       "7   ['Female, DOB 01/03/1996NS looking for $50m te...  \n",
       "8   ['Subject: [External] QQ: S BarXXXX\\n\\nPlease ...  \n",
       "9   ['Subject: [External] Pascarella Case - Potent...  \n",
       "10  ['Subject: [External] XXXXX\\n\\nF/age 35, NS, b...  \n",
       "11  [\"Subject: [External] Tentative case \\n\\nAgent...  \n",
       "12  ['Male- 22 years old state of 50 looking for 2...  \n",
       "13  ['Subject: [External]Female Age 33 \\n\\nThis me...  \n",
       "14  ['Subject: [External] QQ - Zvin\\n\\nPer the age...  \n",
       "15  [\"Subject: [External] #secure# Wong quote\\n\\nW...  \n",
       "16  ['APS SUMMARY\\nPMH: Subarachnoid Bleed 20X2 no...  \n",
       "17  ['Subject: [pSpam] DR QQ\\n\\nFemale, DOB 01/XX/...  \n",
       "18  ['Subject: [External] Quick quote request - FM...  \n",
       "19  ['LN offered Table C due to chronic pain histo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"regexProcessed.csv\", encoding='ISO-8859-1')\n",
    "df = df.iloc[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                50000\n",
       "2               250000\n",
       "3                     \n",
       "4                20000\n",
       "5                     \n",
       "6               500212\n",
       "7             50000000\n",
       "8               300000\n",
       "9                     \n",
       "10              777000\n",
       "11              555000\n",
       "12    TermYear:22years\n",
       "13                    \n",
       "14            59000000\n",
       "15             1555000\n",
       "16                    \n",
       "17            20000000\n",
       "18     TermYear:20year\n",
       "19                    \n",
       "Name: Normalized_Face, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def changeval(ans):\n",
    "    \n",
    "    val = re.sub(\"Face Amount: \",' ',ans)\n",
    "    \n",
    "    val = re.sub(\",\",' ',val)\n",
    "    val = str(re.sub(\" \",'',val))\n",
    "    index = (val.find('$'))\n",
    "    if(index!=-1):\n",
    "        val = val[1:]\n",
    "        \n",
    "    #val = int(val)\n",
    "    return (val)\n",
    "\n",
    "\n",
    "df['Normalized_Face'] = df['Face Amount'].apply(changeval)\n",
    "df['Normalized_Face']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     FEMALE,1977,41,Product Type: Permanent,Face Am...\n",
       "2     male,1921,97, ,Face Amount: 250,000, , , ,['Ge...\n",
       "3     Male,1997,21, , ,200 lb,5 Feet, ,No Medication...\n",
       "4     Male,1945,73, ,Face Amount: $20,000 ,199#,8 Fe...\n",
       "5     Male, , ,Product Type: Permanent, , , , ,['Mal...\n",
       "6     Female,1966,52,Product Type: Term,Face Amount:...\n",
       "7     Female,1996,22,Product Type: Term,Face Amount:...\n",
       "8     MALE,1950,68, ,Face Amount: $300,000, , , ,['S...\n",
       "9     Female,1950,68, , ,255lb, , ,['Subject: [Exter...\n",
       "10    Female,1950,35,Product Type: Term,Face Amount:...\n",
       "11    Male, , ,Product Type: Term,Face Amount: $555,...\n",
       "12    Male, ,22,Product Type: Term,Term Year:  22 ye...\n",
       "13    Female, ,33, , , , ,Non-Tobacco,['Subject: [Ex...\n",
       "14     ,1995,23,Product Type: Term,Face Amount: $59,...\n",
       "15    Male,1995,55,Product Type: Term,Face Amount: $...\n",
       "16     ,1995,23, , , , , ,['APS SUMMARY\\nPMH: Subara...\n",
       "17    Female,1996,22,Product Type: Term,Face Amount:...\n",
       "18    Female,1996,55,Product Type: Term,Term Year: 2...\n",
       "19    Male,1999,19, , ,199#, ,Non-Tobacco,('', 'Fami...\n",
       "Name: ColumnA, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ColumnA'] = df[df.columns[0:]].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "df['ColumnA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Pre-Processed File\n",
    "\n",
    "\n",
    "\n",
    "#process_data(name)\n",
    "\n",
    "#df = pd.read_csv(\"Processed_Data.csv\", encoding='ISO-8859-1')\n",
    "#df[\"Processed\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords,wordnet as wn\n",
    "from nltk.tokenize import wordpunct_tokenize,sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes all punctuations which acts as noise\n",
    "\n",
    "def rem_punt(doc):\n",
    "    ans = re.sub('\"|\\\\n|\\(|\\)|\\.|[$!--+@#:]',' ',doc)\n",
    "    ans = re.sub(' +',' ',ans)\n",
    "    ans = ans.lower()\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Stop words removal using tokenization\n",
    "\n",
    "stop_word = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(document): \n",
    "    lemmy = []\n",
    "    for sent in sent_tokenize(document):\n",
    "        for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "            #print(token,tag)\n",
    "            if token in stop_word:\n",
    "                 continue\n",
    "            lemma = lemmatize(token, tag)\n",
    "            lemmy.append(lemma)\n",
    "    return lemmy\n",
    "\n",
    "#Lemmatization for tokens simplification\n",
    "\n",
    "def lemmatize(token, tag):\n",
    "    tag = {\n",
    "          'N': wn.NOUN,\n",
    "          'V': wn.VERB,\n",
    "          'R': wn.ADV,\n",
    "          'J': wn.ADJ\n",
    "    }.get(tag[0], wn.NOUN)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(token, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[22]:\n",
    "\n",
    "df['Lemmitize'] = df['ColumnA'].apply(rem_punt).apply(tokenize)\n",
    "\n",
    "\n",
    "df.to_csv('NLPProcessed.csv',index=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[25]:\n",
    "\n",
    "df = pd.read_csv('NLPProcessed.csv')\n",
    "\n",
    "\n",
    "# # Statistical Modeling \n",
    "\n",
    "# In[26]:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "X = df['Lemmitize']\n",
    "of = pd.read_csv('raw_data1.csv', encoding='ISO-8859-1')\n",
    "y = of['Offer']\n",
    "#y = df['Offer_noise_free']\n",
    "#lab_y = LabelEncoder()\n",
    "#y = lab_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['female', '1977', '41', 'product', 'type', 'permanent', 'face', 'amount', '50', '000', '200kg', '[', 'gender', 'female', '\\\\\\\\', 'ndob', 'apr', '20', '1977', '\\\\\\\\', 'nproduct', 'type', 'permanent', '\\\\\\\\', 'nface', 'amount', '50', '000', '\\\\\\\\', 'n200kg', '\\\\\\\\', 'n', '\\\\\\\\', 'nhad', 'bypass', '2010', '\\\\\\\\', 'ntakes', 'follow', 'medication', '\\\\\\\\', 'n1', 'metoprolol', 'blood', 'pressure', 'diagnose', '2014', 'take', '25', 'mg', 'daily', '\\\\\\\\', 'n2', 'levothyroxine', 'thyroid', 'diagnose', '2016', 'take', '25', 'mg', 'daily', '\\\\\\\\', 'n', ']', '50000']\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[29]:\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "vect = TfidfVectorizer(max_df=0.8, max_features=15000, min_df=0.01, use_idf=True , ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt \\n%matplotlib inline\\nplt.spy(vect)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "#model1 = XGBClassifier(nthread=4,n_estimators=1000)\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "model2 = GaussianNB()\n",
    "\n",
    "\n",
    "# ExtraTree Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "model3 = RandomForestClassifier(n_estimators=600,n_jobs=-1)\n",
    "\n",
    "# SVM Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model4 = SVC()\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LinearRegression,SGDClassifier,LogisticRegression\n",
    "model5 = LogisticRegression()\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model6 = LinearDiscriminantAnalysis()\n",
    "'''\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.spy(vect)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "name = [] \n",
    "results = []\n",
    "matrix_confusion = []\n",
    "training_time = []\n",
    "prediction_time = []\n",
    "def model_making(model_name, vect , model , X_train , y_train , X_test , y_test):\n",
    "    \n",
    "    t1 =time.time()\n",
    "    clf = make_pipeline(vect,model)\n",
    "    clf.fit(X_train,y_train)\n",
    "    t2 = time.time()\n",
    "    training_time.append(t2-t1)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    pd = clf.predict(X_test)\n",
    "    t2 = time.time()\n",
    "    prediction_time.append(t2-t1)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    name.append(model_name)\n",
    "    results.append(accuracy_score(y_test, y_pred)*100)\n",
    "    matrix_confusion.append(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    #print (\"=====Accuracy Score \", \"{0:.2f}\".format(accuracy_score(y_test, y_pred)*100), \"%\")\n",
    "    #print (\"=====Confusion Matrix\")\n",
    "    #print (confusion_matrix(y_test, y_pred))\n",
    "    #target_names = ['class 0', 'class 1', 'class 2']\n",
    "    #print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n"
     ]
    }
   ],
   "source": [
    "model_making(\"Random Forest\",vect, model3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:119: UserWarning: indptr array has non-integer dtype (float64)\n",
      "  % self.indptr.dtype.name)\n"
     ]
    }
   ],
   "source": [
    "model_making(\"SVM\" , vect, model4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python3/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n"
     ]
    }
   ],
   "source": [
    "model_making(\"Logistic Regression\",vect, model5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_making(\"Naive Bayes\", vect , model2 , X_train, y_train, X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset 19\n",
      "Training dataset:  14\n",
      "Testing dataset:  5 \n",
      "\n",
      "Name                       Accuracy         Training Time(s)    Prediction Time(s) \n",
      " \n",
      "Random Forest               20.000               1.526                        0.209s \n",
      " \n",
      "SVM                         20.000               0.012                        0.004s \n",
      " \n",
      "Logistic Regression         20.000               0.021                        0.003s \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Total dataset\",len(X))\n",
    "print(\"Training dataset: \",len(X_train))\n",
    "print(\"Testing dataset: \",len(X_test),\"\\n\")\n",
    "print(\"{:20} {:^20} {:^20} {:^20}\\n \".format(\"Name\" , \"Accuracy\" , \"Training Time(s)\" , \"Prediction Time(s)\" ) )\n",
    "\n",
    "for i in range(len(name)):\n",
    "    print(\"{:20} {:^20.3f} {:^20.3f} {:20.3f}s \\n \".format(name[i] , results[i] , training_time[i] , prediction_time[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    ['male', '22', 'product', 'type', 'term', 'ter...\n",
       "13    ['1995', '23', 'product', 'type', 'term', 'fac...\n",
       "16    ['female', '1996', '22', 'product', 'type', 't...\n",
       "9     ['female', '1950', '35', 'product', 'type', 't...\n",
       "8                     ['female', '1950', '68', '255lb']\n",
       "Name: Lemmitize, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
